{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b50267b9-6857-4dd5-8e8a-99f862717029",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 1: PDF to Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54b078c-592b-49fd-9974-a40673b7ac57",
   "metadata": {},
   "source": [
    "### Part 1.a: Using PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173836a6-13d0-4aff-912d-ee61b30bad40",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963e348a-b79c-4a45-8d0f-08c7931ed1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfWriter, PdfReader\n",
    "import os, errno\n",
    "import PyPDF2\n",
    "from subprocess import call\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d64ada03-460b-481e-b21a-18337b88f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to split the PDF input file\n",
    "def split(directory, filename):\n",
    "    inputpdf = PdfReader(open(filename, \"rb\"))\n",
    "    try:\n",
    "        os.makedirs(directory)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "    for i in range(len(inputpdf.pages)):\n",
    "        output = PdfWriter()\n",
    "        output.add_page(inputpdf.pages[i])\n",
    "        with open(directory+ \"/%s.pdf\" % i, \"wb\") as outputStream:\n",
    "            output.write(outputStream)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45355f64-5259-4f3a-a55c-9c5db0005d8f",
   "metadata": {},
   "source": [
    "#### Extracting Text from 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e768db12-834e-484f-812a-bb5e232b1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Dataset/2312.15012.pdf\"\n",
    "directory = \"splitted/\"+filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ad4c93-8e83-4015-a182-c53327bebb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PyPDF2._writer.PdfWriter object at 0x000002748D287AD0>\n",
      "The Extracted Text from file is 60101 characters long!\n"
     ]
    }
   ],
   "source": [
    "split(directory, filename)\n",
    "pdfFileObj = open(filename, 'rb')\n",
    "pdfReader = PyPDF2.PdfReader(pdfFileObj)\n",
    "\n",
    "extracted_text = \"\"\n",
    "for i in range(len(pdfReader.pages)):\n",
    "    splitted_file_name = directory + \"/\" + repr(i)\n",
    "    #print(\"-------\",splitted_file_name,\"---------\")\n",
    "    pdfFileObj = open(splitted_file_name+\".pdf\", 'rb')\n",
    "    pdfReader = PyPDF2.PdfReader(pdfFileObj)\n",
    "    text = pdfReader.pages[0].extract_text()\n",
    "    #print(text)\n",
    "    extracted_text += text\n",
    "\n",
    "print(f\"The Extracted Text from file is {len(extracted_text)} characters long!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a09a0a4-8b19-4786-a574-c728d6886f8d",
   "metadata": {},
   "source": [
    "#### Extracting Texts from manually downloaded PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "613d0ddb-17a3-49f2-b399-9d12a96d6edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Filename is :  Dataset\\2312.15012.pdf\n",
      "<PyPDF2._writer.PdfWriter object at 0x00000274A44EEE10>\n",
      "Extracted text length is 60101\n",
      "Filename is :  Dataset\\2312.15018.pdf\n",
      "<PyPDF2._writer.PdfWriter object at 0x00000274A3DDE850>\n",
      "Extracted text length is 51730\n",
      "Filename is :  Dataset\\2312.15038.pdf\n",
      "<PyPDF2._writer.PdfWriter object at 0x00000274A42D5090>\n",
      "Extracted text length is 45931\n",
      "Filename is :  Dataset\\2312.15050.pdf\n",
      "<PyPDF2._writer.PdfWriter object at 0x00000274A4605250>\n",
      "Extracted text length is 70436\n",
      "Filename is :  Dataset\\2312.15056.pdf\n",
      "<PyPDF2._writer.PdfWriter object at 0x00000274A3C2EF10>\n",
      "Extracted text length is 41600\n",
      "Filename is :  Dataset\\2312.15483.pdf\n",
      "<PyPDF2._writer.PdfWriter object at 0x00000274A45FE850>\n",
      "Extracted text length is 35781\n",
      "Filename is :  Dataset\\2312.15761.pdf\n",
      "<PyPDF2._writer.PdfWriter object at 0x00000274A4521A10>\n",
      "Extracted text length is 40405\n",
      "Filename is :  Dataset\\2312.15766.pdf\n",
      "<PyPDF2._writer.PdfWriter object at 0x00000274A423DC50>\n",
      "Extracted text length is 26801\n",
      "Filename is :  Dataset\\2312.15992.pdf\n",
      "<PyPDF2._writer.PdfWriter object at 0x00000274A456B990>\n",
      "Extracted text length is 44285\n",
      "Filename is :  Dataset\\2312.16147.pdf\n",
      "<PyPDF2._writer.PdfWriter object at 0x00000274A3B758D0>\n",
      "Extracted text length is 58041\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "files = [f for f in os.listdir(\"Dataset\") if os.path.isfile(f)]\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "pdf_files = Path(\"Dataset\").glob(\"*.pdf\")\n",
    "\n",
    "df_manual = pd.DataFrame(columns = ['PDF','Text'])\n",
    "\n",
    "for f in pdf_files:\n",
    "    print(\"Filename is : \",f)\n",
    "    directory = \"splitted/\"+filename\n",
    "    split(directory, f)\n",
    "    pdfFileObj = open(filename, 'rb')\n",
    "    pdfReader = PyPDF2.PdfReader(pdfFileObj)\n",
    "\n",
    "    extracted_text = \"\"\n",
    "    for i in range(len(pdfReader.pages)):\n",
    "        splitted_file_name = directory + \"/\" + repr(i)\n",
    "        #print(\"-------\",splitted_file_name,\"---------\")\n",
    "        pdfFileObj = open(splitted_file_name+\".pdf\", 'rb')\n",
    "        pdfReader = PyPDF2.PdfReader(pdfFileObj)\n",
    "        text = pdfReader.pages[0].extract_text()\n",
    "        #print(text)\n",
    "        extracted_text += text\n",
    "\n",
    "    print(f\"Extracted text length is {len(extracted_text)}\")\n",
    "\n",
    "    df_manual.loc[len(df_manual)] = [f,extracted_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80d5cc6d-9d6e-47ca-a0b3-2dd8b9b0b458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDF</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset\\2312.15012.pdf</td>\n",
       "      <td>DRAFT VERSION DECEMBER 27, 2023\\nTypeset using...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset\\2312.15018.pdf</td>\n",
       "      <td>EA51CH25_Gabriel\\nARjats.cls May 12, 2023 18:0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset\\2312.15038.pdf</td>\n",
       "      <td>Prepared for submission to JCAP\\nConstraining ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset\\2312.15050.pdf</td>\n",
       "      <td>ARTICLE\\nLarge planets may not form fractional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset\\2312.15056.pdf</td>\n",
       "      <td>arXiv:2312.15056v1  [astro-ph.CO]  22 Dec 2023...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      PDF                                               Text\n",
       "0  Dataset\\2312.15012.pdf  DRAFT VERSION DECEMBER 27, 2023\\nTypeset using...\n",
       "1  Dataset\\2312.15018.pdf  EA51CH25_Gabriel\\nARjats.cls May 12, 2023 18:0...\n",
       "2  Dataset\\2312.15038.pdf  Prepared for submission to JCAP\\nConstraining ...\n",
       "3  Dataset\\2312.15050.pdf  ARTICLE\\nLarge planets may not form fractional...\n",
       "4  Dataset\\2312.15056.pdf  arXiv:2312.15056v1  [astro-ph.CO]  22 Dec 2023..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_manual.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f12a209-87c2-47c6-85a0-707d88359854",
   "metadata": {},
   "source": [
    "### Part 1.b: Using EasyOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dfac3d6-ccbf-462e-90b5-1ffbc24ebdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz #PyMuPDF\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40e0d7aa-aa94-47ed-9be4-9dfd6a679b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_images(pdf_path):\n",
    "    images = []\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(pdf_document.page_count):\n",
    "        page = pdf_document[page_num]\n",
    "        image = page.get_pixmap()\n",
    "        img = Image.frombytes(\"RGB\", (image.width, image.height), image.samples)\n",
    "        images.append(img)\n",
    "\n",
    "    pdf_document.close()\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f8e7c2f-cfaf-41da-9650-862593ba241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_images(images, language='en'):\n",
    "    reader = easyocr.Reader([language])\n",
    "\n",
    "    extracted_text = \"\"\n",
    "    for img in images:\n",
    "        img_array = np.array(img)\n",
    "        result = reader.readtext(img_array)\n",
    "        for detection in result:\n",
    "            text = detection[1]\n",
    "            extracted_text += text + \"\\n\"\n",
    "\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb19339d-f3e5-4686-bf63-e48bea9d838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_text_to_file(text, file_path):\n",
    "    with open(file_path, 'a', encoding='utf-8') as text_file:\n",
    "        text_file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7efc82-fe17-4dd3-a46f-5cb3acd5f870",
   "metadata": {},
   "source": [
    "#### Extract Text with EasyOCR from 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "313e566d-08dc-44f0-ad75-f81a246167f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"ExtraFiles/sample.pdf\"\n",
    "directory = \"splitted/\"+filename\n",
    "directory_text = \"textOCR/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55bbae1f-4792-432d-989f-26cf24b043cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PyPDF2._writer.PdfWriter object at 0x00000274A9BCB410>\n",
      "------- splitted/ExtraFiles/sample.pdf/0 ---------\n",
      "Length of each pdf is : 1\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "split(directory, filename)\n",
    "pdfFileObj = open(filename, 'rb')\n",
    "pdfReader = PyPDF2.PdfReader(pdfFileObj)\n",
    "\n",
    "for i in range(len(pdfReader.pages)):\n",
    "    splitted_file_name = directory + \"/\" + repr(i)\n",
    "    print(\"-------\",splitted_file_name,\"---------\")\n",
    "    pdf_images = pdf_to_images(splitted_file_name+\".pdf\")\n",
    "    print(\"Length of each pdf is :\", len(pdf_images))\n",
    "\n",
    "    extracted_text = extract_text_from_images(pdf_images)\n",
    "    print(\"=========================================\")\n",
    "    #print(extracted_text)\n",
    "    \n",
    "    output_filename = directory_text+repr(i)+\".txt\"\n",
    "    save_text_to_file(extracted_text, output_filename)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5766159a-5740-466c-846a-df7a84ed139c",
   "metadata": {},
   "source": [
    "Since EasyOCR takes a long while to process a single file, we switch to Teserract OCR for processing all the downloaded PDF files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1471762-21a9-4ba5-8e2d-ded5831e8422",
   "metadata": {},
   "source": [
    "### Part 1.c: Using TesseractOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6311dbed-d4dc-4e30-b779-0bae0cc2dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "from PIL.JpegImagePlugin import JpegImageFile\n",
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d126fc7-c114-4536-81b7-a41337501e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image(path: str) -> JpegImageFile:\n",
    "    return Image.open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "575ef329-fc0e-43ca-9100-b51a7ff6ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TesseractOCR(image: JpegImageFile) -> str:\n",
    "    return pytesseract.image_to_string(image, lang=\"eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44200e0f-689e-43df-a93c-a74904c44d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EasyOCR(image: JpegImageFile) -> str:\n",
    "    reader = easyocr.Reader(['en']) # initialize OCR\n",
    "    result = reader.readtext(image) # input image\n",
    "    return \"\\n\".join([res[1] for res in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8efd4c35-48c7-456b-8068-bb313931f61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def pdf_to_images(pdf_path, output_folder):\n",
    "    pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    extracted_text = \"\"\n",
    "    for page_number in range(pdf_document.page_count):\n",
    "        page = pdf_document[page_number]\n",
    "        image = page.get_pixmap()\n",
    "        \n",
    "        image_path = f\"{output_folder}/page_{page_number + 1}.jpg\"\n",
    "        image.save(image_path)\n",
    "\n",
    "        text = pytesseract.image_to_string(Image.open(image_path))\n",
    "        extracted_text += text + \"\\n\"\n",
    "    \n",
    "    pdf_document.close()\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeb0cef-6209-4863-a3d1-b6398f608eae",
   "metadata": {},
   "source": [
    "#### Extracting Text from 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "462dcee3-c76f-45ec-9342-5f67a3d41f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "text = pdf_to_images(\"ExtraFiles/automatic text summarization.pdf\", \"pdf2jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1efd8004-82e0-4b71-a0a8-c9236a267a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text length is 92200\n"
     ]
    }
   ],
   "source": [
    "print(f\"Extracted text length is {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "276b13d0-8378-4a3b-8aa0-90a92d58a241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 5 agua st i pain 15.202) 1257\n",
      "\n",
      "ome the seman confusion caused by ambiguus orsynonymous\n",
      "‘words (Wr etal2017) Without uring NUP te generated xtc\n",
      "Se smmaties may sles om lack of caheson and semantics\n",
      "‘a if texts canain mall tople, the generated surnry\n",
      "‘ay not be balanced (Guts Lal 2010,\n",
      "\n",
      "‘hllenges Relate wo Evaluation ofthe Generated Summary\n",
      "valuaingsunumares eter automa or manual) ail\n",
      "fairs tts very llengigtodein and we goad standard\n",
      "{orevalate whether he summaries generated fom the ATS S/=\n",
      "tems ae goad enough (Lotte 2017) a2) ery hard\n",
      "{o'fed oat what a tel (or even covet) sunt) Hs becuse\n",
      "fe ATS systems can generate good Sumsmavies that ate dierent\n",
      "faethe human gencatd suas (Moraanch lila\n",
      "2017) Humans ae diferent and they Sele ently erat\n",
      "Seetences for the erative statis aed ay paapate the\n",
      "Stacie summaries na completely dierent wa 1s ery ub\n",
      "jective ta dents good smy Meer, anal esas\n",
      "‘ay ot be stable for al yes of uma! el, 2017)\n",
      "“here is ned to propose new aptaaces and selon fo the\n",
      "ulate evaluation ofthe computer generated summa,\n",
      "\n",
      "Declaration of Competing Interest\n",
      "\n",
      "“Te ators declare ha they have o now competing Ba\n",
      "ial lteret opts rlshpe that cou have appeted\n",
      "to tuence te work reported a ths pape\n",
      "\n",
      "‘ii ting unas odet tre amurin Sour a\n",
      "seni Enmore 1 age BOL. Quy att\n",
      "‘ummaianan ota pale sea pemiatc, pti Recs\n",
      "‘eto QA: tae D281 A hb soph fo te ten\n",
      "Emre th icon we awit esr\n",
      "‘nites ee ett ‘wen Aas\n",
      "\n",
      "sare, te Rem 1 3-294\n",
      "\"Sen mats Abe tet omarion Fe greed he TS\n",
      "iia nero ei sn Comanese\n",
      "avant Mo, (2015, xan amped ec\n",
      "i yt Sem pce k HES\n",
      "\n",
      "was fpr nti a gon a\n",
      "aie ge Mts tal A i Co\n",
      "sited ern pon Be\n",
      "sus ah GD ce en appa naan\n",
      "id el ret Sa Uns ee aoe\n",
      "\n",
      "Sante tips fey aang mt\n",
      "\n",
      "sal ha, Pat) gh: aco\n",
      "Sirwm to,se 100 ps fuaoro taps\n",
      "\n",
      "ee harm A 08) AAT A opi dei\n",
      "Siesta eee ekerein\n",
      "svar eS Ss tna sme ste\n",
      "vn SA eg RS AES deo\n",
      "“ms tin Some Eos a ers\n",
      "GED tpn rsd pts Pe ce\n",
      "i ge el eC wa ana\n",
      "Jets rp pee hereto Ht at\n",
      "‘ge eae rer aes ets\n",
      "wal pana erga aa ns\n",
      "ntl ted at geal Sa\n",
      "ng Rc 6 an, | 0, Tae\n",
      "er te ge Se Sa\n",
      "‘orn. aA Coma § 202 side denen eee te\n",
      "Ehlert ences |\" nen\n",
      "coe Rel tance\n",
      "Soa a Sve\n",
      "co Sars hein a ¢ 0..\n",
      "‘a neg tec espn norton: como\n",
      "‘og ST Ren a tok RE Arce ee\n",
      "Seert meat ena eaee\n",
      "alte SBE So Sanne\n",
      "in nei etna © Sey\n",
      "Ten py St Se ta\n",
      "teres bean. Ronare RT ESal Te ot\n",
      "Tay tes wane sp nd te aa\n",
      "ei’ font San eT\n",
      "borer er a\n",
      "Fp ee pen pn\n",
      "Sy iedntgo co srs a ih\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "print(pytesseract.image_to_string(Image.open('pdf2jpg\\page_22.jpg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338ca039-8135-47b8-a6ad-01d4bdb5b0ca",
   "metadata": {},
   "source": [
    "#### Extracting Text from all manually downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bc50643-5778-47b9-ae4e-ad14d19450f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename is :  Dataset\\2312.15012.pdf\n",
      "Extracted text length is 91894\n",
      "Filename is :  Dataset\\2312.15018.pdf\n",
      "Extracted text length is 62539\n",
      "Filename is :  Dataset\\2312.15038.pdf\n",
      "Extracted text length is 89613\n",
      "Filename is :  Dataset\\2312.15050.pdf\n",
      "Extracted text length is 81765\n",
      "Filename is :  Dataset\\2312.15056.pdf\n",
      "Extracted text length is 100000\n",
      "Filename is :  Dataset\\2312.15483.pdf\n",
      "Extracted text length is 95009\n",
      "Filename is :  Dataset\\2312.15761.pdf\n",
      "Extracted text length is 96581\n",
      "Filename is :  Dataset\\2312.15766.pdf\n",
      "Extracted text length is 78141\n",
      "Filename is :  Dataset\\2312.15992.pdf\n",
      "Extracted text length is 72725\n",
      "Filename is :  Dataset\\2312.16147.pdf\n",
      "Extracted text length is 85607\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "files = [f for f in os.listdir(\"Dataset\") if os.path.isfile(f)]\n",
    "from pathlib import Path\n",
    "\n",
    "pdf_files = Path(\"Dataset\").glob(\"*.pdf\")\n",
    "\n",
    "df_manual_1 = pd.DataFrame(columns = ['PDF','Text'])\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "\n",
    "for f in pdf_files:\n",
    "    print(\"Filename is : \",f)\n",
    "    text = pdf_to_images(f, \"pdf2jpg\")\n",
    "    #print(\"Text is : \",text)\n",
    "\n",
    "    text2 = \"\"\n",
    "    for img in os.listdir('pdf2jpg/'):\n",
    "        #print(\"Image is \\n\",img)\n",
    "\n",
    "        img_path = 'pdf2jpg/'+img\n",
    "        text2 += pytesseract.image_to_string(Image.open(img_path))\n",
    "\n",
    "    print(f\"Extracted text length is {len(text2)}\")\n",
    "\n",
    "    df_manual_1.loc[len(df_manual_1)] = [f,text2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecc74099-23fe-407e-a2d5-72b5b02562a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDF</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset\\2312.15012.pdf</td>\n",
       "      <td>3\\n\\n5\\n\\nastro-ph.GA] 22 Dec 20:\\n\\narXiv:231...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset\\2312.15018.pdf</td>\n",
       "      <td>iggy ANNUAL\\nREVIEWS\\n\\nAnmual Review of Earth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset\\2312.15038.pdf</td>\n",
       "      <td>23\\n\\nDec 20:\\n\\nDl\\n\\nv1 [astro-ph.CO]\\n\\n038...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset\\2312.15050.pdf</td>\n",
       "      <td>nature\\n\\nCOMMUNICATIONS\\n\\nARTICLE\\nEEE orev\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset\\2312.15056.pdf</td>\n",
       "      <td>2023\\n\\n6v1 [astro-ph.CO] 22 Dec\\n\\n5\\n\\n312.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dataset\\2312.15483.pdf</td>\n",
       "      <td>3v1\\n\\n4\\n\\n5\\n\\narXiv:2312.1\\n\\nObservational...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dataset\\2312.15761.pdf</td>\n",
       "      <td>23\\n\\nDec 20:\\n\\n25\\n\\nastro-ph.CO]\\n\\n76lvi |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dataset\\2312.15766.pdf</td>\n",
       "      <td>2023\\n\\n5 Dec\\n\\nastro-ph.CO] 2\\n\\narXiv:2312....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dataset\\2312.15992.pdf</td>\n",
       "      <td>arXiv:2312.15992v1 [astro-ph.CO] 26 Dec 2023\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dataset\\2312.16147.pdf</td>\n",
       "      <td>023\\n\\n2\\n\\narXiv:2312.16147v1 [astro-ph.CO] 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      PDF                                               Text\n",
       "0  Dataset\\2312.15012.pdf  3\\n\\n5\\n\\nastro-ph.GA] 22 Dec 20:\\n\\narXiv:231...\n",
       "1  Dataset\\2312.15018.pdf  iggy ANNUAL\\nREVIEWS\\n\\nAnmual Review of Earth...\n",
       "2  Dataset\\2312.15038.pdf  23\\n\\nDec 20:\\n\\nDl\\n\\nv1 [astro-ph.CO]\\n\\n038...\n",
       "3  Dataset\\2312.15050.pdf  nature\\n\\nCOMMUNICATIONS\\n\\nARTICLE\\nEEE orev\\...\n",
       "4  Dataset\\2312.15056.pdf  2023\\n\\n6v1 [astro-ph.CO] 22 Dec\\n\\n5\\n\\n312.1...\n",
       "5  Dataset\\2312.15483.pdf  3v1\\n\\n4\\n\\n5\\n\\narXiv:2312.1\\n\\nObservational...\n",
       "6  Dataset\\2312.15761.pdf  23\\n\\nDec 20:\\n\\n25\\n\\nastro-ph.CO]\\n\\n76lvi |...\n",
       "7  Dataset\\2312.15766.pdf  2023\\n\\n5 Dec\\n\\nastro-ph.CO] 2\\n\\narXiv:2312....\n",
       "8  Dataset\\2312.15992.pdf  arXiv:2312.15992v1 [astro-ph.CO] 26 Dec 2023\\n...\n",
       "9  Dataset\\2312.16147.pdf  023\\n\\n2\\n\\narXiv:2312.16147v1 [astro-ph.CO] 2..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_manual_1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a335617b-a406-492e-b184-4531fd015977",
   "metadata": {},
   "source": [
    "As we see that PyPDF2 is the fastest method for extracting text from reserach papers, we will work with the DataFrame df_manual instead of df_manual_1 for the subsequent steps!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc8b42-18c6-47c4-9194-8bf40e242596",
   "metadata": {},
   "source": [
    "## Part 2: Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3debd2a-4c87-446b-9e50-ba7e51bcf775",
   "metadata": {},
   "source": [
    "#### Part 2.a: BART Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "314687c2-54bf-4244-8152-cab205d754e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfquery import PDFQuery\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e5332d-5d5b-4068-b823-44a084d1c17a",
   "metadata": {},
   "source": [
    "#### Summarizing 1 paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dc7c145-f791-49d9-9f32-21c2fe8716e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_summarize = \"We aim to create a Deep Learning-based Text Summarization and Question-Answering model. With the introduction and rapid adoption of Large Language Models, especially the widespread use of GPT4All, research into Text Summarization and Question Answering Systems (QAS) has increased multifold. While LLM-based applications like ChatGPT allows users to enter textual prompt, there is often restriction in terms of the number of words they can write to set the context and only premium versions of such applications permit users to enter multimodal input data like images, PDFs, et cetera. We aim to create a model that will allow for both text and PDF input and help users understand the document, summarize it, and ask follow-up questions out of their input text or PDF file. Text summarization is a valuable tool for condensing extensive raw data into human-readable information. It falls into the category of Extractive and Abstractive methods. Extractive methods of summarization minimize the burden of summarization by choosing from the actual text a subset of sentences that are relevant. Three key components in QA systems include question classification, information retrieval, and answer extraction. Question classification categorizes submitted questions based on their types, a critical role. Information retrieval is crucial in QA as it determines if correct answers exist in a document. Answer extraction seeks to retrieve the user's requested answer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24f5c657-dfdc-411e-809f-6d5b042ebfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We aim to create a Deep Learning-based Text Summarization and Question-Answering model. The model will allow for both text and PDF input and help users understand the document, summarize it, and ask follow-up questions.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(text_to_summarize, max_length=1024, return_tensors=\"pt\", truncation=True)\n",
    "#print(inputs)\n",
    "\n",
    "# Generate Summary\n",
    "summary_ids = model.generate(inputs[\"input_ids\"], num_beams=2, min_length=30, max_length=100)\n",
    "y = tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac549ef7-db9b-42ee-a223-b651314a9d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rouge-1': {'r': 0.43333333333333335, 'p': 0.43333333333333335, 'f': 0.4333333283333334}, 'rouge-2': {'r': 0.125, 'p': 0.12121212121212122, 'f': 0.12307691807810672}, 'rouge-l': {'r': 0.36666666666666664, 'p': 0.36666666666666664, 'f': 0.36666666166666667}}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from rouge import Rouge\n",
    "\n",
    "# Define the generated summary and the reference summary\n",
    "generated_summary = y\n",
    "reference_summary = \"We have created a model which will allow users to enter PDF files as input and be able to summarize those file through Text Summarization and do Question Answering with those generated summaries.\"\n",
    "# Initialize the ROUGE object\n",
    "rouge = Rouge()\n",
    "# Calculate ROUGE for the generated and reference summaries\n",
    "scores = rouge.get_scores(generated_summary, reference_summary)\n",
    "# Print the results\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eee317d-7ea6-4062-8963-dfff87ffa98c",
   "metadata": {},
   "source": [
    "#### Summarizing Manually Downloaded PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c63b842b-ba34-45cc-be2b-46747e6310a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 File Done!\n",
      "1 File Done!\n",
      "1 File Done!\n",
      "1 File Done!\n",
      "1 File Done!\n",
      "1 File Done!\n",
      "1 File Done!\n",
      "1 File Done!\n",
      "1 File Done!\n",
      "1 File Done!\n"
     ]
    }
   ],
   "source": [
    "df_summary = pd.DataFrame(columns=['PDF','Summary'])\n",
    "\n",
    "for index,row in df_manual.iterrows():\n",
    "    inputs = tokenizer(row['Text'], max_length=1024, return_tensors=\"pt\", truncation=True)\n",
    "    #print(inputs)\n",
    "\n",
    "    # Generate Summary\n",
    "    summary_ids = model.generate(inputs[\"input_ids\"], num_beams=2, min_length=30, max_length=100)\n",
    "    y = tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "    #print(y)\n",
    "    print(\"1 File Done!\")\n",
    "\n",
    "    df_summary.loc[len(df_summary)] = [row['PDF'],y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6571d725-f17b-4780-ad28-9f94b75d9811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDF</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset\\2312.15012.pdf</td>\n",
       "      <td>Two Distinct Classes of Quiescent Galaxies at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset\\2312.15018.pdf</td>\n",
       "      <td>The Annual Review of Earth and Planetary Scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset\\2312.15038.pdf</td>\n",
       "      <td>Constraining general multi-field              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset\\2312.15050.pdf</td>\n",
       "      <td>Large planets may not form fractionally largem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset\\2312.15056.pdf</td>\n",
       "      <td>We discuss the present state and planned updat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dataset\\2312.15483.pdf</td>\n",
       "      <td>Observational constraints on extended Proca-Nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dataset\\2312.15761.pdf</td>\n",
       "      <td>Higher order clustering of Ly αforest provides...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dataset\\2312.15766.pdf</td>\n",
       "      <td>Inflation with the Gauss-Bonnet term is a two-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dataset\\2312.15992.pdf</td>\n",
       "      <td>The galaxy bispectrum in the Spherical Fourier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dataset\\2312.16147.pdf</td>\n",
       "      <td>Theory of quantum field theory and cosmologica...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      PDF                                            Summary\n",
       "0  Dataset\\2312.15012.pdf  Two Distinct Classes of Quiescent Galaxies at ...\n",
       "1  Dataset\\2312.15018.pdf  The Annual Review of Earth and Planetary Scien...\n",
       "2  Dataset\\2312.15038.pdf  Constraining general multi-field              ...\n",
       "3  Dataset\\2312.15050.pdf  Large planets may not form fractionally largem...\n",
       "4  Dataset\\2312.15056.pdf  We discuss the present state and planned updat...\n",
       "5  Dataset\\2312.15483.pdf  Observational constraints on extended Proca-Nu...\n",
       "6  Dataset\\2312.15761.pdf  Higher order clustering of Ly αforest provides...\n",
       "7  Dataset\\2312.15766.pdf  Inflation with the Gauss-Bonnet term is a two-...\n",
       "8  Dataset\\2312.15992.pdf  The galaxy bispectrum in the Spherical Fourier...\n",
       "9  Dataset\\2312.16147.pdf  Theory of quantum field theory and cosmologica..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e0cad4-e1cc-400a-bee6-73472029ad1c",
   "metadata": {},
   "source": [
    "#### Part 2.b: BERT Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "410aef81-6d1e-4907-a1ef-d7be903da982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We aim to create a Deep Learning-based Text Summarization and Question-Answering model. With the introduction and rapid adoption of Large Language Models, especially the widespread use of GPT4All, research into Text Summarization and Question Answering Systems (QAS) has increased multifold. We aim to create a model that will allow for both text and PDF input and help users understand the document, summarize it, and ask follow-up questions out of their input text or PDF file.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from summarizer.bert import Summarizer\n",
    "\n",
    "model = Summarizer()\n",
    "model(text_to_summarize)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5699ec9c-c40d-4990-9d63-a122287868b9",
   "metadata": {},
   "source": [
    "As BERT Summarizer takes a long time for just 1 summarization, we switch to Sentence BERT for the summarization of all PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e712ea-f8cf-4701-8f49-cd850ec00469",
   "metadata": {},
   "source": [
    "#### Sentence BERT Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44733d2d-da9f-41cb-b114-f3d1bac3562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarizer.sbert import SBertSummarizer\n",
    "\n",
    "model = SBertSummarizer('paraphrase-MiniLM-L6-v2')\n",
    "result = model(text_to_summarize, num_sentences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aec64697-f534-41be-96d7-df09049d8cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We aim to create a Deep Learning-based Text Summarization and Question-Answering model. With the introduction and rapid adoption of Large Language Models, especially the widespread use of GPT4All, research into Text Summarization and Question Answering Systems (QAS) has increased multifold. Three key components in QA systems include question classification, information retrieval, and answer extraction.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d878a5df-de63-42e2-a699-a3aedd0d2291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "# define the source text and reference text\n",
    "reference_text = [\"We have created a model which will allow users to enter PDF files as input and be able to summarize those file through Text Summarization and do Question Answering with those generated summaries.\"]\n",
    "# define the text generated by the model\n",
    "generated_text = [result]\n",
    "# calculate the BLEU score\n",
    "score = bleu_score(generated_text, reference_text)\n",
    "print(f'BLEU Score: {score*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "310cbf4c-c8f2-4a34-b76f-536741d67914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 File Done!\n",
      "1 File Done!\n",
      "1 File Done!\n",
      "1 File Done!\n",
      "1 File Done!\n",
      "1 File Done!\n",
      "1 File Done!\n",
      "1 File Done!\n",
      "1 File Done!\n",
      "1 File Done!\n"
     ]
    }
   ],
   "source": [
    "df_summary_1 = pd.DataFrame(columns=['PDF','Summary'])\n",
    "\n",
    "for index,row in df_manual.iterrows():\n",
    "    result = model(row['Text'], num_sentences=3)\n",
    "    print(\"1 File Done!\")\n",
    "\n",
    "    df_summary_1.loc[len(df_summary_1)] = [row['PDF'],result]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7325378-89b6-42b1-857e-93db47b05393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDF</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset\\2312.15012.pdf</td>\n",
       "      <td>DRAFT VERSION DECEMBER 27, 2023\\nTypeset using...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset\\2312.15018.pdf</td>\n",
       "      <td>EA51CH25_Gabriel\\nARjats.cls May 12, 2023 18:0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset\\2312.15038.pdf</td>\n",
       "      <td>We investigate how well the SPHEREx all-sky su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset\\2312.15050.pdf</td>\n",
       "      <td>ARTICLE\\nLarge planets may not form fractional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset\\2312.15056.pdf</td>\n",
       "      <td>CO]  22 Dec 2023Present and future of CosmoLat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dataset\\2312.15483.pdf</td>\n",
       "      <td>Observational constraints on extended Proca-Nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dataset\\2312.15761.pdf</td>\n",
       "      <td>94, 247\\n©SAIt 2023 Memorie della\\nHigher orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dataset\\2312.15766.pdf</td>\n",
       "      <td>TU-1217\\nKEK-QUP-0036\\nProbing Gauss-Bonnet-Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dataset\\2312.15992.pdf</td>\n",
       "      <td>In this work we develop a formalism for\\nthe b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dataset\\2312.16147.pdf</td>\n",
       "      <td>Draft version December 27, 2023\\nTypeset using...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      PDF                                            Summary\n",
       "0  Dataset\\2312.15012.pdf  DRAFT VERSION DECEMBER 27, 2023\\nTypeset using...\n",
       "1  Dataset\\2312.15018.pdf  EA51CH25_Gabriel\\nARjats.cls May 12, 2023 18:0...\n",
       "2  Dataset\\2312.15038.pdf  We investigate how well the SPHEREx all-sky su...\n",
       "3  Dataset\\2312.15050.pdf  ARTICLE\\nLarge planets may not form fractional...\n",
       "4  Dataset\\2312.15056.pdf  CO]  22 Dec 2023Present and future of CosmoLat...\n",
       "5  Dataset\\2312.15483.pdf  Observational constraints on extended Proca-Nu...\n",
       "6  Dataset\\2312.15761.pdf  94, 247\\n©SAIt 2023 Memorie della\\nHigher orde...\n",
       "7  Dataset\\2312.15766.pdf  TU-1217\\nKEK-QUP-0036\\nProbing Gauss-Bonnet-Co...\n",
       "8  Dataset\\2312.15992.pdf  In this work we develop a formalism for\\nthe b...\n",
       "9  Dataset\\2312.16147.pdf  Draft version December 27, 2023\\nTypeset using..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e83b37c-d829-4196-b04c-9357103235f6",
   "metadata": {},
   "source": [
    "#### Visualizing Summaries: Word CLoud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28d1e082-5229-49ae-9ef4-bde5a296d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8822fe09-24b0-4913-8693-22332c9aed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stopword list:\n",
    "STOP_WORDS.add('otter')\n",
    "stopwords = set(list(STOP_WORDS) +list(stopwords.words()))\n",
    "stopwords.update([\"br\", \"href\", 'https'])\n",
    "stopwords.update(stopwords)\n",
    "\n",
    "textt = \" \".join(desc for desc in df_summary.Summary)\n",
    "print(textt)\n",
    "wordcloud = WordCloud(stopwords=stopwords,background_colur='white').generate(textt)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e8736e-f807-44a3-8375-f7274ed152d2",
   "metadata": {},
   "source": [
    "### Part 3: Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bf2ac1-f11d-4d3c-98e2-d535020b58b2",
   "metadata": {},
   "source": [
    "#### Part 3.a: Langchain QA"
   ]
  },
  {
   "cell_type": "raw",
   "id": "262f26ec-ec6e-431c-a7c1-1b3cb0911652",
   "metadata": {},
   "source": [
    "Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b360287e-28bd-4884-a8c2-de64d8a9b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loaders = PyPDFLoader(\"automatic text summarization.pdf\")\n",
    "\n",
    "#Load the document by calling loader.load()\n",
    "pages = loaders.load()\n",
    "\n",
    "print(len(pages))\n",
    "print(pages[0].page_content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941259a6-c155-4c6d-ba16-ec6a6de52cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "\n",
    "loaders = [PyPDFLoader(\"long-sample.pdf\")]\n",
    "\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a15ac9af-a1ca-4542-a3ba-d2805b8f6ddf",
   "metadata": {},
   "source": [
    "Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d0f0f-f15a-4605-bd9c-057ad213da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Text Splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n",
    "\n",
    "#Create a split of the document using the text splitter\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29789c96-968a-4d83-8a39-2ea756de9800",
   "metadata": {},
   "source": [
    "Vector Store & Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c467c0-39f1-44fd-a7d2-4a7bfc84da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe54779-d19c-4f57-b634-9e19f7e5acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef27077b-5707-43e5-9a8d-42f759c3f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = './chroma_db'\n",
    "\n",
    "# Create the vector store\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae2f33bd-5c1b-404c-9296-ff7678d22b40",
   "metadata": {},
   "source": [
    "Retrieval QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7305d6-4675-40fd-92bb-61c633f85cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did it say about Generalized Linear Models ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4cb9ad-ba13-49f1-b45d-beaef389b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b251103-a70d-46ac-ad32-25601286512d",
   "metadata": {},
   "source": [
    "Using StuffChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c9f9d0-ab1d-40f6-a8be-54a7feba6091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f07e74-8f2b-44f4-8582-669b5677113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilaize chain\n",
    "# Set return_source_documents to True to get the source document\n",
    "# Set chain_type to prompt template defines\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a854a43b-7c29-4742-b9ea-72d0268415f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": question})\n",
    "\n",
    "# Check the result of the query\n",
    "result[\"result\"]\n",
    "\n",
    "# Check the source document from where we\n",
    "result[\"source_documents\"][0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5588024-1981-4f84-a25b-fa139133b222",
   "metadata": {},
   "source": [
    "Using Map Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbed6b4-0156-4caf-addd-97e153d3f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type=\"map_reduce\"\n",
    ")\n",
    "result = qa_chain_mr({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc1be2d4-d8cf-4619-ab95-724ac39f90db",
   "metadata": {},
   "source": [
    "Using Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e061d9-3451-42b6-aad6-b602d7df22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_r = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type=\"refine\"\n",
    ")\n",
    "result = qa_chain_r({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c049dc9-4607-471a-9da1-c9938ddfa82f",
   "metadata": {},
   "source": [
    "#### Part 3.b: Falcon QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7925071b-7cb0-4993-af8a-a5e38a2eeb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20 august 2011'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "question = \"On which date did Swansea City play its first Premier League game?\"\n",
    "context = \"In 2011, a Welsh club participated in the Premier League for the first time after Swansea City gained promotion. The first Premier League match to be played outside England was Swansea City's home match at the Liberty Stadium against Wigan Athletic on 20 August 2011. In 2012\\u201313, Swansea qualified for the Europa League by winning the League Cup. The number of Welsh clubs in the Premier League increased to two for the first time in 2013\\u201314, as Cardiff City gained promotion, but Cardiff City was relegated after its maiden season.\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Falconsai/question_answering_v2\")\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"Falconsai/question_answering_v2\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "answer_start_index = outputs.start_logits.argmax()\n",
    "answer_end_index = outputs.end_logits.argmax()\n",
    "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "tokenizer.decode(predict_answer_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fbb870-8c93-46e3-bf19-9141ee482b6f",
   "metadata": {},
   "source": [
    "#### Part 3.c BERT QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59aadf47-d67d-4d72-9d5e-8f8f40451604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "weight_path = \"kaporter/bert-base-uncased-finetuned-squad\"\n",
    "# loading tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(weight_path)\n",
    "#loading the model\n",
    "model = BertForQuestionAnswering.from_pretrained(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9802955-ffa0-4fb8-87e7-f0669214bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How many parameters does BERT-large have?\"\n",
    "context = \"BERT-large is really big... it has 24-layers and an embedding size of 1,024, for a total of 340M parameters! Altogether it is 1.34GB, so expect it to take a couple minutes to download to your Colab instance.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "192db018-be7e-42ce-ab8d-226c42b87766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have about 70 tokens generated\n",
      "Predicted answer: 340\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(question, context)\n",
    "print (f'We have about {len(input_ids)} tokens generated')\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "sep_idx = tokens.index('[SEP]')\n",
    "\n",
    "# we will provide including [SEP] token which seperates question from context and 1 for rest.\n",
    "token_type_ids = [0 for i in range(sep_idx+1)] + [1 for i in range(sep_idx+1,len(tokens))]\n",
    "\n",
    "# Run our example through the model.\n",
    "out = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "            token_type_ids=torch.tensor([token_type_ids]))\n",
    "\n",
    "start_logits,end_logits = out['start_logits'],out['end_logits']\n",
    "# Find the tokens with the highest `start` and `end` scores.\n",
    "answer_start = torch.argmax(start_logits)\n",
    "answer_end = torch.argmax(end_logits)\n",
    "\n",
    "ans = ''.join(tokens[answer_start:answer_end])\n",
    "print('Predicted answer:', ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c325c7c8-d3f9-4b15-aba7-7c0c69218a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the AIM of this project?\"\n",
    "context = \"We aim to create a Deep Learning-based Text Summarization and Question-Answering model. The model will allow for both text and PDF input and help users understand the document, summarize it, and ask follow-up questions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2993cea1-7544-4159-ad67-3ad2fc6b296d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have about 59 tokens generated\n",
      "Predicted answer: tocreateadeeplearning-basedtextsum##mar##izationandquestion-answeringmodel.themodelwillallowforbothtextandpdfinputandhelpusersunderstandthedocument,sum##mar##izeit,andaskfollow-up\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(question, context)\n",
    "print (f'We have about {len(input_ids)} tokens generated')\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "sep_idx = tokens.index('[SEP]')\n",
    "\n",
    "# we will provide including [SEP] token which seperates question from context and 1 for rest.\n",
    "token_type_ids = [0 for i in range(sep_idx+1)] + [1 for i in range(sep_idx+1,len(tokens))]\n",
    "\n",
    "# Run our example through the model.\n",
    "out = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "            token_type_ids=torch.tensor([token_type_ids]))\n",
    "\n",
    "start_logits,end_logits = out['start_logits'],out['end_logits']\n",
    "# Find the tokens with the highest `start` and `end` scores.\n",
    "answer_start = torch.argmax(start_logits)\n",
    "answer_end = torch.argmax(end_logits)\n",
    "\n",
    "ans = ''.join(tokens[answer_start:answer_end])\n",
    "print('Predicted answer:', ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd7fa5-7562-41b4-8dc7-033dadd9b241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
